{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception, VGG16, ResNet50, InceptionV3\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import layers, models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2\n",
    "seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TRAIN_CROP_PATH = os.path.join(DATA_PATH, 'train_crop_299')\n",
    "TEST_CROP_PATH = os.path.join(DATA_PATH, 'test_crop_299')\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n",
    "image_size=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(train_df, val_df, train_dir, valid_dir, test_df, test_dir, image_size, batch_size,valid_batch_size,\n",
    "                 scale='rgb', target='class'):\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=train_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        #preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True)\n",
    "\n",
    "    )\n",
    "    validation_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=valid_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size,image_size),\n",
    "        batch_size=valid_batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        #processing_function=preprocess_input\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=test_dir,\n",
    "        x_col='img_file',\n",
    "        y_col=None,\n",
    "        target_size= (image_size,image_size),\n",
    "        color_mode=scale,\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #preprocessing_function=preprocess_input\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"class\"] = df_train[\"class\"].astype('str')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_test = df_test[['img_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traindf(df, train_size=0.6, stratify=True, label='class'):\n",
    "    target = None\n",
    "    if stratify:\n",
    "        target = df[label].values\n",
    "    X_train, X_val = train_test_split(df, train_size=train_size, random_state=SEED, stratify=target)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = split_traindf(df_train.iloc[:, :], train_size=0.7, stratify=True)\n",
    "nb_train_sample = X_train.shape[0]\n",
    "nb_validation_sample = X_val.shape[0]\n",
    "nb_test_sample = df_test.shape[0]\n",
    "scale = 'rgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "valid_batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6993 validated image filenames belonging to 196 classes.\n",
      "Found 2997 validated image filenames belonging to 196 classes.\n",
      "Found 6150 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    scale=scale,\n",
    "                                                    valid_batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(app, image_size, opt, num_class=196, lr=0.0001):\n",
    "    if app=='Xception':\n",
    "        application = Xception\n",
    "    elif app=='VGG16':\n",
    "        application = VGG16\n",
    "    elif app=='ResNet50':\n",
    "        application = ResNet50\n",
    "    elif app=='InceptionV3':\n",
    "        application = InceptionV3\n",
    "    base_model = application(weights='imagenet', input_shape=(image_size,image_size,3), include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    \n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(512, activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(num_class, activation='softmax'))\n",
    "    #model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_dir, model_name):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m%d_%H%M\")\n",
    "    model_path = model_dir + date_time + model_name + '.hdf5'\n",
    "    print('>>model path to save: {}'.format(model_path))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>model path to save: ../model/0711_0659xception_ratiotest_0705.hdf5\n",
      ">>get model completed\n"
     ]
    }
   ],
   "source": [
    "model_type='Xception'\n",
    "image_size = 299 if model_type=='Xception' or model_type=='InceptionV3' else 224\n",
    "histories=[]\n",
    "patient = 3\n",
    "lr = 0.0001\n",
    "epoch=300\n",
    "model_dir = '../model/'\n",
    "model_name = 'xception_ratiotest_0705'\n",
    "model_path = get_model_path(model_dir, model_name)\n",
    "model = get_model(app=model_type, image_size=image_size, opt=optimizers.RMSprop(lr=lr), lr=lr)\n",
    "print('>>get model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback(patient, model_path, lr, total_count):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss',\n",
    "                      patience=patient,\n",
    "                      mode='min',\n",
    "                      verbose=1),\n",
    "        #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "        ModelCheckpoint(filepath=model_path,\n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='min'),\n",
    "        ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                          factor = 0.5, patience = patient / 2,\n",
    "                          min_lr=0.00001, verbose=1, mode='min'),\n",
    "\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "438/438 [==============================] - 183s 417ms/step - loss: 5.0728 - acc: 0.0387 - val_loss: 4.3821 - val_acc: 0.1532\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.38208, saving model to ../model/0711_0659xception_ratiotest_0705.hdf5\n",
      "Epoch 2/300\n",
      "216/438 [=============>................] - ETA: 1:27 - loss: 4.2614 - acc: 0.1534"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, valid_batch_size),\n",
    "    verbose=1,\n",
    "    callbacks=get_callback(patient, model_path, lr, len(X_train))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use 5000 images\n",
    "baseline + ratio image test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
