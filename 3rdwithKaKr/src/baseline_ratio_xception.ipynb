{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception, VGG16, ResNet50, InceptionV3\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import layers, models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2\n",
    "seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TRAIN_CROP_PATH = os.path.join(DATA_PATH, 'train_crop_ratio')\n",
    "TEST_CROP_PATH = os.path.join(DATA_PATH, 'test_crop_ratio')\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n",
    "image_size=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(train_df, val_df, train_dir, valid_dir, test_df, test_dir, image_size, batch_size,valid_batch_size,\n",
    "                 scale='rgb', target='class'):\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=train_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        #preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True)\n",
    "\n",
    "    )\n",
    "    validation_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=valid_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size,image_size),\n",
    "        batch_size=valid_batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        #processing_function=preprocess_input\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=test_dir,\n",
    "        x_col='img_file',\n",
    "        y_col=None,\n",
    "        target_size= (image_size,image_size),\n",
    "        color_mode=scale,\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #preprocessing_function=preprocess_input\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"class\"] = df_train[\"class\"].astype('str')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_test = df_test[['img_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traindf(df, train_size=0.6, stratify=True, label='class'):\n",
    "    target = None\n",
    "    if stratify:\n",
    "        target = df[label].values\n",
    "    X_train, X_val = train_test_split(df, train_size=train_size, random_state=SEED, stratify=target)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[:5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = split_traindf(df_train.iloc[:, :], train_size=0.8, stratify=True)\n",
    "nb_train_sample = X_train.shape[0]\n",
    "nb_validation_sample = X_val.shape[0]\n",
    "nb_test_sample = df_test.shape[0]\n",
    "scale = 'rgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "valid_batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 196 classes.\n",
      "Found 2004 validated image filenames belonging to 196 classes.\n",
      "Found 6169 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    scale=scale,\n",
    "                                                    valid_batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(app, image_size, opt, num_class=196, lr=0.0001):\n",
    "    if app=='Xception':\n",
    "        application = Xception\n",
    "    elif app=='VGG16':\n",
    "        application = VGG16\n",
    "    elif app=='ResNet50':\n",
    "        application = ResNet50\n",
    "    elif app=='InceptionV3':\n",
    "        application = InceptionV3\n",
    "    base_model = application(weights='imagenet', input_shape=(image_size,image_size,3), include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    \n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(512, activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(num_class, activation='softmax'))\n",
    "    #model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_dir, model_name):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m%d_%H%M\")\n",
    "    model_path = model_dir + date_time + model_name + '.hdf5'\n",
    "    print('>>model path to save: {}'.format(model_path))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>model path to save: ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      ">>get model completed\n"
     ]
    }
   ],
   "source": [
    "model_type='Xception'\n",
    "image_size = 299 if model_type=='Xception' or model_type=='InceptionV3' else 224\n",
    "histories=[]\n",
    "patient = 3\n",
    "lr = 0.0001\n",
    "epoch=300\n",
    "model_dir = '../xception_model/'\n",
    "model_name = 'xception_ratiotest_0705'\n",
    "model_path = get_model_path(model_dir, model_name)\n",
    "model = get_model(app=model_type, image_size=image_size, opt=optimizers.RMSprop(lr=lr), lr=lr)\n",
    "print('>>get model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback(patient, model_path, lr, total_count):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss',\n",
    "                      patience=patient,\n",
    "                      mode='min',\n",
    "                      verbose=1),\n",
    "        #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "        ModelCheckpoint(filepath=model_path,\n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='min'),\n",
    "        ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                          factor = 0.5, patience = patient / 2,\n",
    "                          min_lr=0.00001, verbose=1, mode='min'),\n",
    "\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "501/501 [==============================] - 202s 404ms/step - loss: 5.0377 - acc: 0.0383 - val_loss: 4.3581 - val_acc: 0.1248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.35806, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 2/300\n",
      "501/501 [==============================] - 200s 399ms/step - loss: 3.9901 - acc: 0.1673 - val_loss: 3.1381 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.35806 to 3.13813, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 3/300\n",
      "501/501 [==============================] - 200s 400ms/step - loss: 2.9648 - acc: 0.3594 - val_loss: 2.2891 - val_acc: 0.5205\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.13813 to 2.28910, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 4/300\n",
      "501/501 [==============================] - 201s 400ms/step - loss: 2.1121 - acc: 0.5454 - val_loss: 1.5959 - val_acc: 0.6552\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.28910 to 1.59593, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 5/300\n",
      "501/501 [==============================] - 201s 400ms/step - loss: 1.4380 - acc: 0.6972 - val_loss: 1.1538 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59593 to 1.15375, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 6/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.9664 - acc: 0.7954 - val_loss: 0.8391 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15375 to 0.83906, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 7/300\n",
      "501/501 [==============================] - 201s 400ms/step - loss: 0.6528 - acc: 0.8593 - val_loss: 0.7607 - val_acc: 0.7944\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.83906 to 0.76069, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 8/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.4403 - acc: 0.9044 - val_loss: 0.6633 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.76069 to 0.66330, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 9/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.3160 - acc: 0.9292 - val_loss: 0.5634 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.66330 to 0.56339, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 10/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.2282 - acc: 0.9489 - val_loss: 0.5350 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56339 to 0.53505, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 11/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.1719 - acc: 0.9596 - val_loss: 0.5281 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.53505 to 0.52807, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 12/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.1351 - acc: 0.9682 - val_loss: 0.5673 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.52807\n",
      "Epoch 13/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.1085 - acc: 0.9732 - val_loss: 0.5605 - val_acc: 0.8398\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52807\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 14/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0613 - acc: 0.9870 - val_loss: 0.4797 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52807 to 0.47971, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 15/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0470 - acc: 0.9894 - val_loss: 0.4846 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47971\n",
      "Epoch 16/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0327 - acc: 0.9944 - val_loss: 0.5099 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47971\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 17/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0242 - acc: 0.9948 - val_loss: 0.4660 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.47971 to 0.46603, saving model to ../xception_model/0705_0325xception_ratiotest_0705.hdf5\n",
      "Epoch 18/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0201 - acc: 0.9955 - val_loss: 0.4768 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.46603\n",
      "Epoch 19/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0206 - acc: 0.9951 - val_loss: 0.4770 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.46603\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 20/300\n",
      "501/501 [==============================] - 201s 401ms/step - loss: 0.0128 - acc: 0.9981 - val_loss: 0.4750 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.46603\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, valid_batch_size),\n",
    "    verbose=1,\n",
    "    callbacks=get_callback(patient, model_path, lr, len(X_train))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use 5000 images\n",
    "baseline + ratio image test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
