{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/neuralspace/kaggle-1-winning-approach-for-image-classification-challenge-9c1188157a86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception, VGG16, ResNet50, InceptionV3\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import layers, models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 2\n",
    "seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'class.csv', 'test.zip', 'train_crop_299', 'train.zip', 'sample_submission.csv', 'train', '.ipynb_checkpoints', 'train.csv', 'test.csv', 'test_crop_299', 'train_crop_224', 'test_crop_224']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_boxing_img(img_name, margin=8, size=(299, 299)) :\n",
    "    if img_name.split('_')[0] == \"train\" :\n",
    "        PATH = TRAIN_IMG_PATH\n",
    "        data = df_train\n",
    "    elif img_name.split('_')[0] == \"test\" :\n",
    "        PATH = TEST_IMG_PATH\n",
    "        data = df_test\n",
    "        \n",
    "    img = PIL.Image.open(os.path.join(PATH, img_name))\n",
    "    pos = data.loc[data[\"img_file\"] == img_name, \\\n",
    "                   ['bbox_x1','bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n",
    "\n",
    "    width, height = img.size\n",
    "    x1 = max(0, pos[0] - margin)\n",
    "    y1 = max(0, pos[1] - margin)\n",
    "    x2 = min(pos[2] + margin, width)\n",
    "    y2 = min(pos[3] + margin, height)\n",
    "\n",
    "    return img.crop((x1,y1,x2,y2)).resize(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(image_size, TRAIN_CROP_PATH, TEST_CROP_PATH):\n",
    "    if not os.path.exists(TRAIN_CROP_PATH):\n",
    "        os.mkdir(TRAIN_CROP_PATH)\n",
    "        print('>>mkdir {}'.format(TRAIN_CROP_PATH))\n",
    "        for i, row in df_train.iterrows():\n",
    "            cropped = crop_resize_boxing_img(row['img_file'], size=(image_size, image_size))\n",
    "            cropped.save(TRAIN_CROP_PATH+\"/\"+row['img_file'])\n",
    "        print('>>train_crop completed')\n",
    "    else:\n",
    "        print('>>train_crop exist')\n",
    "    if not os.path.exists(TEST_CROP_PATH):\n",
    "        print('>>mkdir {}'.format(TEST_CROP_PATH))\n",
    "        os.mkdir(TEST_CROP_PATH)\n",
    "        for i, row in df_test.iterrows():\n",
    "            cropped = crop_resize_boxing_img(row['img_file'], size=(image_size, image_size))\n",
    "            cropped.save(TEST_CROP_PATH+\"/\"+row['img_file'])\n",
    "        print('>>test_crop  completed')\n",
    "    else:\n",
    "        print('>>test_crop exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traindf(df, train_size=0.6, stratify=True, label='class'):\n",
    "    target = None\n",
    "    if stratify:\n",
    "        target = df[label].values\n",
    "    X_train, X_val = train_test_split(df, train_size=train_size, random_state=SEED, stratify=target)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/yu4u/cutout-random-erasing\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        input_img = preprocess_input(input_img)\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(train_df, val_df, train_dir, valid_dir, test_df, test_dir, image_size, batch_size,valid_batch_size,\n",
    "                 scale='rgb', target='class'):\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=train_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True)\n",
    "\n",
    "    )\n",
    "    validation_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=valid_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size,image_size),\n",
    "        batch_size=valid_batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True,\n",
    "        processing_function=preprocess_input\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=test_dir,\n",
    "        x_col='img_file',\n",
    "        y_col=None,\n",
    "        target_size= (image_size,image_size),\n",
    "        color_mode=scale,\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(app, image_size, opt, num_class=196, lr=0.0001):\n",
    "    if app=='Xception':\n",
    "        application = Xception\n",
    "    elif app=='VGG16':\n",
    "        application = VGG16\n",
    "    elif app=='ResNet50':\n",
    "        application = ResNet50\n",
    "    elif app=='InceptionV3':\n",
    "        application = InceptionV3\n",
    "    base_model = application(weights='imagenet', input_shape=(image_size,image_size,3), include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    \n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(1024, activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_class, activation='softmax'))\n",
    "    #model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_dir, model_name):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m%d_%H%M\")\n",
    "    model_path = model_dir + date_time + model_name + '.hdf5'\n",
    "    print('>>model path to save: {}'.format(model_path))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history, model_name):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "    plt.title('Training and validation accuracy' + model_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Traing loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Trainging and validation loss' + model_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "def cosine_decay_with_warmup(global_step,\n",
    "                             learning_rate_base,\n",
    "                             total_steps,\n",
    "                             warmup_learning_rate=0.0,\n",
    "                             warmup_steps=0,\n",
    "                             hold_base_rate_steps=0):\n",
    "    \"\"\"Cosine decay schedule with warm up period.\n",
    "\n",
    "    Cosine annealing learning rate as described in:\n",
    "      Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts.\n",
    "      ICLR 2017. https://arxiv.org/abs/1608.03983\n",
    "    In this schedule, the learning rate grows linearly from warmup_learning_rate\n",
    "    to learning_rate_base for warmup_steps, then transitions to a cosine decay\n",
    "    schedule.\n",
    "\n",
    "    Arguments:\n",
    "        global_step {int} -- global step.\n",
    "        learning_rate_base {float} -- base learning rate.\n",
    "        total_steps {int} -- total number of training steps.\n",
    "\n",
    "    Keyword Arguments:\n",
    "        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n",
    "        warmup_steps {int} -- number of warmup steps. (default: {0})\n",
    "        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n",
    "                                    before decaying. (default: {0})\n",
    "    Returns:\n",
    "      a float representing learning rate.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if warmup_learning_rate is larger than learning_rate_base,\n",
    "        or if warmup_steps is larger than total_steps.\n",
    "    \"\"\"\n",
    "\n",
    "    if total_steps < warmup_steps:\n",
    "        raise ValueError('total_steps must be larger or equal to '\n",
    "                         'warmup_steps.')\n",
    "    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(\n",
    "        np.pi *\n",
    "        (global_step - warmup_steps - hold_base_rate_steps\n",
    "         ) / float(total_steps - warmup_steps - hold_base_rate_steps)))\n",
    "    if hold_base_rate_steps > 0:\n",
    "        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n",
    "                                 learning_rate, learning_rate_base)\n",
    "    if warmup_steps > 0:\n",
    "        if learning_rate_base < warmup_learning_rate:\n",
    "            raise ValueError('learning_rate_base must be larger or equal to '\n",
    "                             'warmup_learning_rate.')\n",
    "        slope = (learning_rate_base - warmup_learning_rate) / warmup_steps\n",
    "        warmup_rate = slope * global_step + warmup_learning_rate\n",
    "        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n",
    "                                 learning_rate)\n",
    "    return np.where(global_step > total_steps, 0.0, learning_rate)\n",
    "\n",
    "\n",
    "class WarmUpCosineDecayScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"Cosine decay with warmup learning rate scheduler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learning_rate_base,\n",
    "                 total_steps,\n",
    "                 global_step_init=0,\n",
    "                 warmup_learning_rate=0.0,\n",
    "                 warmup_steps=0,\n",
    "                 hold_base_rate_steps=0,\n",
    "                 verbose=0):\n",
    "        \"\"\"Constructor for cosine decay with warmup learning rate scheduler.\n",
    "\n",
    "    Arguments:\n",
    "        learning_rate_base {float} -- base learning rate.\n",
    "        total_steps {int} -- total number of training steps.\n",
    "\n",
    "    Keyword Arguments:\n",
    "        global_step_init {int} -- initial global step, e.g. from previous checkpoint.\n",
    "        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n",
    "        warmup_steps {int} -- number of warmup steps. (default: {0})\n",
    "        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n",
    "                                    before decaying. (default: {0})\n",
    "        verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
    "        \"\"\"\n",
    "\n",
    "        super(WarmUpCosineDecayScheduler, self).__init__()\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.global_step = global_step_init\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.hold_base_rate_steps = hold_base_rate_steps\n",
    "        self.verbose = verbose\n",
    "        self.learning_rates = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.global_step = self.global_step + 1\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.learning_rates.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = cosine_decay_with_warmup(global_step=self.global_step,\n",
    "                                      learning_rate_base=self.learning_rate_base,\n",
    "                                      total_steps=self.total_steps,\n",
    "                                      warmup_learning_rate=self.warmup_learning_rate,\n",
    "                                      warmup_steps=self.warmup_steps,\n",
    "                                      hold_base_rate_steps=self.hold_base_rate_steps)\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nBatch %05d: setting learning '\n",
    "                  'rate to %s.' % (self.global_step + 1, lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warmup_lr(base_lr, total_count, warmup_epoch=25):\n",
    "    # Number of warmup epochs.\n",
    "    warmup_epoch = 25\n",
    "\n",
    "    total_steps = int(epoch * len(X_train) / batch_size)\n",
    "    # Compute the number of warmup batches.\n",
    "    warmup_steps = int(warmup_epoch * len(X_train) / batch_size)\n",
    "    # Compute the number of warmup batches.\n",
    "    warmup_batches = warmup_epoch * len(X_train) / batch_size\n",
    "\n",
    "    # Create the Learning rate scheduler.\n",
    "    warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=lr,\n",
    "                                            total_steps=total_steps,\n",
    "                                            warmup_learning_rate=0.0,\n",
    "                                            warmup_steps=warmup_steps,\n",
    "                                            hold_base_rate_steps=0)\n",
    "    return warm_up_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback(patient, model_path, lr, total_count):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss',\n",
    "                      patience=patient,\n",
    "                      mode='min',\n",
    "                      verbose=1),\n",
    "        #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "        ModelCheckpoint(filepath=model_path,\n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='min'),\n",
    "        get_warmup_lr(lr, total_count)\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_119(df_train, keep=50, class_num='119'):\n",
    "    class_119_idx = np.array(df_train[df_train['class']==class_num].index)\n",
    "    np.random.shuffle(class_119_idx)\n",
    "    return df_train.drop(class_119_idx[keep:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type='Xception'\n",
    "image_size = 299 if model_type=='Xception' or model_type=='InceptionV3' else 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>train_crop exist\n",
      ">>test_crop exist\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CROP_PATH = os.path.join(DATA_PATH, 'train_crop_' + str(image_size))\n",
    "TEST_CROP_PATH = os.path.join(DATA_PATH, 'test_crop_' + str(image_size))\n",
    "crop_img(image_size, TRAIN_CROP_PATH, TEST_CROP_PATH)\n",
    "df_train[\"class\"] = df_train[\"class\"].astype('str')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_test = df_test[['img_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>befor drop : 10016\n",
      ">>after drop : 9982\n"
     ]
    }
   ],
   "source": [
    "print('>>befor drop : {}'.format(df_train.shape[0]))\n",
    "df_train = drop_119(df_train)\n",
    "print('>>after drop : {}'.format(df_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    zca_whitening=True\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "valid_batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7985 validated image filenames belonging to 196 classes.\n",
      "Found 1997 validated image filenames belonging to 196 classes.\n",
      "Found 6169 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = split_traindf(df_train.iloc[:, :], train_size=0.8, stratify=True)\n",
    "nb_train_sample = X_train.shape[0]\n",
    "nb_validation_sample = X_val.shape[0]\n",
    "nb_test_sample = df_test.shape[0]\n",
    "scale = 'rgb'\n",
    "#scale = 'rgb'\n",
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    scale=scale,\n",
    "                                                    valid_batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightsclaer(values, total_count):\n",
    "    new_val = [total_count/x for x in values]\n",
    "    min_val = min(new_val)\n",
    "    new_val = [x/min_val for x in new_val]\n",
    "    return new_val\n",
    "labels_count = dict()\n",
    "for label in X_train['class'].unique():\n",
    "    labels_count[label] = sum(X_train['class']==label)\n",
    "class_weight = None\n",
    "#class_weight = weightsclaer(labels_count.values(), X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>model path to save: ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      ">>get model completed\n"
     ]
    }
   ],
   "source": [
    "histories=[]\n",
    "patient = 10\n",
    "lr = 0.0001\n",
    "epoch=300\n",
    "model_dir = '../xception_model/'\n",
    "model_name = '_3rd_Xception_cosinedecay'\n",
    "model_path = get_model_path(model_dir, model_name)\n",
    "model = get_model(app=model_type, image_size=image_size, opt=optimizers.RMSprop(lr=lr), lr=lr)\n",
    "print('>>get model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 5.6393 - acc: 0.0051 - val_loss: 5.3774 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.37742, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 2/300\n",
      "1997/1997 [==============================] - 257s 129ms/step - loss: 5.5265 - acc: 0.0063 - val_loss: 5.2446 - val_acc: 0.0125\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.37742 to 5.24461, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 3/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 5.3945 - acc: 0.0055 - val_loss: 5.0814 - val_acc: 0.0351\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.24461 to 5.08142, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 4/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 5.1970 - acc: 0.0131 - val_loss: 4.8026 - val_acc: 0.0876\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.08142 to 4.80256, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 5/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 4.9543 - acc: 0.0270 - val_loss: 4.4251 - val_acc: 0.1412\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.80256 to 4.42508, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 6/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 4.6463 - acc: 0.0496 - val_loss: 3.9487 - val_acc: 0.1858\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.42508 to 3.94865, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 7/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 4.2372 - acc: 0.0898 - val_loss: 3.4099 - val_acc: 0.2794\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.94865 to 3.40990, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 8/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 3.7391 - acc: 0.1516 - val_loss: 2.8560 - val_acc: 0.3565\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.40990 to 2.85595, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 9/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 3.1553 - acc: 0.2520 - val_loss: 2.2206 - val_acc: 0.4912\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.85595 to 2.22059, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 10/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 2.5539 - acc: 0.3761 - val_loss: 1.7194 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.22059 to 1.71943, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 11/300\n",
      "1997/1997 [==============================] - 261s 131ms/step - loss: 1.9660 - acc: 0.5119 - val_loss: 1.2180 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.71943 to 1.21804, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 12/300\n",
      "1997/1997 [==============================] - 260s 130ms/step - loss: 1.4233 - acc: 0.6510 - val_loss: 0.8869 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.21804 to 0.88688, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 13/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 1.0061 - acc: 0.7524 - val_loss: 0.6499 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88688 to 0.64988, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 14/300\n",
      "1997/1997 [==============================] - 260s 130ms/step - loss: 0.7026 - acc: 0.8300 - val_loss: 0.5485 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.64988 to 0.54851, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 15/300\n",
      "1997/1997 [==============================] - 260s 130ms/step - loss: 0.4855 - acc: 0.8843 - val_loss: 0.4793 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.54851 to 0.47933, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 16/300\n",
      "1997/1997 [==============================] - 263s 132ms/step - loss: 0.3469 - acc: 0.9142 - val_loss: 0.4492 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.47933 to 0.44917, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 17/300\n",
      "1997/1997 [==============================] - 263s 132ms/step - loss: 0.2519 - acc: 0.9384 - val_loss: 0.4463 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.44917 to 0.44630, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 18/300\n",
      "1997/1997 [==============================] - 264s 132ms/step - loss: 0.1923 - acc: 0.9531 - val_loss: 0.4606 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44630\n",
      "Epoch 19/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1486 - acc: 0.9637 - val_loss: 0.4858 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44630\n",
      "Epoch 20/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1266 - acc: 0.9662 - val_loss: 0.5100 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44630\n",
      "Epoch 21/300\n",
      " 129/1997 [>.............................] - ETA: 3:57 - loss: 0.1064 - acc: 0.9709"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9f9df5710bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, valid_batch_size),\n",
    "    verbose=1,\n",
    "    callbacks=get_callback(patient, model_path, lr, len(X_train)),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7985 validated image filenames belonging to 196 classes.\n",
      "Found 1997 validated image filenames belonging to 196 classes.\n",
      "Found 6169 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    scale=scale,\n",
    "                                                    valid_batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=lr), metrics=['acc'])\n",
    "model.load_weights(model_path)#0.34662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1997/1997 [==============================] - 264s 132ms/step - loss: 0.1853 - acc: 0.9569 - val_loss: 0.4661 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46615, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 2/300\n",
      "1997/1997 [==============================] - 256s 128ms/step - loss: 0.1899 - acc: 0.9546 - val_loss: 0.4574 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46615 to 0.45740, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 3/300\n",
      "1997/1997 [==============================] - 256s 128ms/step - loss: 0.1838 - acc: 0.9563 - val_loss: 0.4592 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45740\n",
      "Epoch 4/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 0.1794 - acc: 0.9557 - val_loss: 0.4454 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45740 to 0.44542, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 5/300\n",
      "1997/1997 [==============================] - 257s 129ms/step - loss: 0.1706 - acc: 0.9627 - val_loss: 0.4409 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44542 to 0.44088, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 6/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 0.1716 - acc: 0.9587 - val_loss: 0.4346 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44088 to 0.43458, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 7/300\n",
      "1997/1997 [==============================] - 258s 129ms/step - loss: 0.1654 - acc: 0.9623 - val_loss: 0.4291 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43458 to 0.42909, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 8/300\n",
      "1997/1997 [==============================] - 259s 130ms/step - loss: 0.1545 - acc: 0.9675 - val_loss: 0.4228 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42909 to 0.42275, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 9/300\n",
      "1997/1997 [==============================] - 260s 130ms/step - loss: 0.1535 - acc: 0.9648 - val_loss: 0.4179 - val_acc: 0.8803\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.42275 to 0.41789, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 10/300\n",
      "1997/1997 [==============================] - 261s 131ms/step - loss: 0.1524 - acc: 0.9678 - val_loss: 0.4127 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.41789 to 0.41271, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 11/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1428 - acc: 0.9701 - val_loss: 0.4089 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41271 to 0.40887, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 12/300\n",
      "1997/1997 [==============================] - 261s 131ms/step - loss: 0.1431 - acc: 0.9700 - val_loss: 0.4065 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.40887 to 0.40647, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 13/300\n",
      "1997/1997 [==============================] - 261s 131ms/step - loss: 0.1328 - acc: 0.9718 - val_loss: 0.4047 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40647 to 0.40467, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 14/300\n",
      "1997/1997 [==============================] - 261s 131ms/step - loss: 0.1339 - acc: 0.9731 - val_loss: 0.3989 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40467 to 0.39891, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 15/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1261 - acc: 0.9763 - val_loss: 0.3973 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39891 to 0.39730, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 16/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1231 - acc: 0.9783 - val_loss: 0.3941 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39730 to 0.39412, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 17/300\n",
      "1997/1997 [==============================] - 263s 131ms/step - loss: 0.1161 - acc: 0.9806 - val_loss: 0.3900 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.39412 to 0.38998, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 18/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1297 - acc: 0.9775 - val_loss: 0.3893 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38998 to 0.38933, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 19/300\n",
      "1997/1997 [==============================] - 263s 132ms/step - loss: 0.1287 - acc: 0.9768 - val_loss: 0.3885 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.38933 to 0.38854, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 20/300\n",
      "1997/1997 [==============================] - 262s 131ms/step - loss: 0.1288 - acc: 0.9738 - val_loss: 0.3864 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38854 to 0.38641, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 21/300\n",
      "1997/1997 [==============================] - 263s 132ms/step - loss: 0.1258 - acc: 0.9780 - val_loss: 0.3833 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.38641 to 0.38326, saving model to ../xception_model/0625_0435_3rd_Xception_cosinedecay.hdf5\n",
      "Epoch 22/300\n",
      "1997/1997 [==============================] - 263s 131ms/step - loss: 0.1247 - acc: 0.9758 - val_loss: 0.3845 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38326\n",
      "Epoch 23/300\n",
      "1997/1997 [==============================] - 263s 131ms/step - loss: 0.1213 - acc: 0.9776 - val_loss: 0.3838 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38326\n",
      "Epoch 24/300\n",
      " 376/1997 [====>.........................] - ETA: 3:24 - loss: 0.1171 - acc: 0.9814"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6156ad789167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patient = 10\n",
    "history_2nd = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, valid_batch_size),\n",
    "    verbose=1,\n",
    "    callbacks=get_callback(patient, model_path, lr, len(X_train)),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path) #loss 0.29xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "prediction = model.predict_generator(\n",
    "    generator=test_gen,\n",
    "    steps = get_steps(nb_test_sample, batch_size),\n",
    "    verbose=1\n",
    ")\n",
    "predicted_class_indices=np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generator class dictionary mapping\n",
    "\n",
    "labels = (train_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions_labels = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "submission[\"class\"] = predictions_labels\n",
    "submission_fname = \"submissions/submissions_{}.csv\".format(model_name)\n",
    "submission.to_csv(submission_fname, index=False)\n",
    "submission.head()\n",
    "print('[*]sumission saved at {}'.format(submission_fname))\n",
    "#89318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base : batch 8 + more augmentation  + nodecay  + imgsize (224->299)\n",
    "\n",
    "rmsprop ->\n",
    "\n",
    "adam -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image generate \n",
    "\n",
    "tip1 : https://towardsdatascience.com/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6\n",
    "\n",
    "tip2 : https://imgaug.readthedocs.io/en/latest/source/installation.html#installation-in-pip\n",
    "\n",
    "\n",
    "cosine learning rate decay\n",
    "\n",
    "https://www.dlology.com/blog/bag-of-tricks-for-image-classification-with-convolutional-neural-networks-in-keras/\n",
    "\n",
    "https://machinelearningmastery.com/snapshot-ensemble-deep-learning-neural-network/\n",
    "\n",
    "\n",
    "progressive\n",
    "\n",
    "https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20\n",
    "\n",
    "\n",
    "check error visual\n",
    "\n",
    "https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
    "\n",
    "\n",
    "fine tuning-inception v3\n",
    "\n",
    "https://gist.github.com/didacroyo/839bd1dbb67463df8ba8fb14eb3fde0c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image data generator\n",
    "\n",
    "contrast_stretching=True, adaptive_equalization=True, histogram_equalization=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
