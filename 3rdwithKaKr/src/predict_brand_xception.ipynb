{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 2\n",
    "seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_crop', 'test', 'class.csv', 'test.zip', 'train.zip', 'sample_submission.csv', 'train', '.ipynb_checkpoints', 'train.csv', 'test.csv', 'train_crop']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TRAIN_CROP_PATH = os.path.join(DATA_PATH, 'train_crop')\n",
    "TEST_CROP_PATH = os.path.join(DATA_PATH, 'test_crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_boxing_img(img_name, margin=8, size=(299, 299)) :\n",
    "    if img_name.split('_')[0] == \"train\" :\n",
    "        PATH = TRAIN_IMG_PATH\n",
    "        data = df_train\n",
    "    elif img_name.split('_')[0] == \"test\" :\n",
    "        PATH = TEST_IMG_PATH\n",
    "        data = df_test\n",
    "        \n",
    "    img = PIL.Image.open(os.path.join(PATH, img_name))\n",
    "    pos = data.loc[data[\"img_file\"] == img_name, \\\n",
    "                   ['bbox_x1','bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n",
    "\n",
    "    width, height = img.size\n",
    "    x1 = max(0, pos[0] - margin)\n",
    "    y1 = max(0, pos[1] - margin)\n",
    "    x2 = min(pos[2] + margin, width)\n",
    "    y2 = min(pos[3] + margin, height)\n",
    "\n",
    "    return img.crop((x1,y1,x2,y2)).resize(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img():\n",
    "    if not os.path.exists(TRAIN_CROP_PATH):\n",
    "        os.mkdir(TRAIN_CROP_PATH)\n",
    "        print('>>mkdir {}'.format(TRAIN_CROP_PATH))\n",
    "        for i, row in df_train.iterrows():\n",
    "            cropped = crop_resize_boxing_img(row['img_file'])\n",
    "            cropped.save(TRAIN_CROP_PATH+\"/\"+row['img_file'])\n",
    "        print('>>train_crop completed')\n",
    "    else:\n",
    "        print('>>train_crop exist')\n",
    "    if not os.path.exists(TEST_CROP_PATH):\n",
    "        print('>>mkdir {}'.format(TEST_CROP_PATH))\n",
    "        os.mkdir(TEST_CROP_PATH)\n",
    "        for i, row in df_test.iterrows():\n",
    "            cropped = crop_resize_boxing_img(row['img_file'])\n",
    "            cropped.save(TEST_CROP_PATH+\"/\"+row['img_file'])\n",
    "        print('>>test_crop  completed')\n",
    "    else:\n",
    "        print('>>test_crop exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traindf(df, train_size=0.6, stratify=True, label='class'):\n",
    "    target = None\n",
    "    if stratify:\n",
    "        target = df[label].values\n",
    "    X_train, X_val = train_test_split(df, train_size=train_size, random_state=SEED, stratify=target)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(train_df, val_df, train_dir, valid_dir, test_df, test_dir, image_size, batch_size,valid_batch_size,\n",
    "                 scale='rgb', target='class'):\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=train_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True\n",
    "    )\n",
    "    validation_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=valid_dir,\n",
    "        x_col = 'img_file',\n",
    "        y_col = target,\n",
    "        target_size=(image_size,image_size),\n",
    "        batch_size=valid_batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=3,\n",
    "        color_mode=scale,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=test_dir,\n",
    "        x_col='img_file',\n",
    "        y_col=None,\n",
    "        target_size= (image_size,image_size),\n",
    "        color_mode=scale,\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_class=196):\n",
    "    application = Xception\n",
    "    base_model = application(weights='imagenet', input_shape=(image_size,image_size,3), include_top=False)\n",
    "    #base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(1024, activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_class, activation='softmax'))\n",
    "    #model.summary()\n",
    "    optimizer = optimizers.RMSprop(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_dir, model_name):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m%d_%H%M\")\n",
    "    model_path = model_dir + date_time + model_name + '.hdf5'\n",
    "    print('>>model path to save: {}'.format(model_path))\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history, model_name):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "    plt.title('Training and validation accuracy' + model_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Traing loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Trainging and validation loss' + model_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(df_train, df_class):\n",
    "    df_class = df_class.copy()\n",
    "    df_train = df_train.copy()\n",
    "    import re\n",
    "    p = re.compile('[A-Z]*[a-z]* ')\n",
    "    new = [x[0] for x in df_class['name'].str.findall(p)]\n",
    "    df_class['name'] = new\n",
    "    df_class=df_class.rename(columns = {'id':'class'})\n",
    "    df_class['class'] = df_class['class'].astype(str)\n",
    "    df_train = pd.merge(df_train, df_class, on='class')\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>train_crop exist\n",
      ">>test_crop exist\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n",
    "\n",
    "crop_img()\n",
    "\n",
    "df_train[\"class\"] = df_train[\"class\"].astype('str')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_test = df_test[['img_file']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict car brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = get_class_name(df_train, df_class)\n",
    "indexs=[]\n",
    "for name in df_train['name'].unique():\n",
    "    max_val = 20\n",
    "    label_idx = np.argwhere(df_train['name']== name)[:,0]\n",
    "    np.random.shuffle(label_idx)\n",
    "    indexs.extend(label_idx[:max_val])\n",
    "df_train_brand = df_train.iloc[indexs,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470\n",
      "8546\n",
      "6169\n",
      "Found 1470 validated image filenames belonging to 49 classes.\n",
      "Found 8546 validated image filenames belonging to 49 classes.\n",
      "Found 6169 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "batch_size = 4\n",
    "valid_batch_size = 16\n",
    "#X_train, X_val = split_traindf(df_train_brand.iloc[:, :], train_size=1.0, stratify=True, label='name')\n",
    "X_val = df_train[~df_train.index.isin(indexs)]\n",
    "X_train = df_train_brand\n",
    "nb_train_sample = X_train.shape[0]\n",
    "nb_validation_sample = X_val.shape[0]\n",
    "nb_test_sample = df_test.shape[0]\n",
    "print(nb_train_sample)\n",
    "print(nb_validation_sample)\n",
    "print(nb_test_sample)\n",
    "scale = 'rgb'\n",
    "#scale = 'rgb'\n",
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    valid_batch_size=valid_batch_size,\n",
    "                                                    scale=scale,\n",
    "                                                   target='name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories=[]\n",
    "patient = 3\n",
    "lr = 0.00005\n",
    "model_dir = '../xception_model/'\n",
    "model_name = '_3rd_xception_brand_preidct'\n",
    "epoch=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>model path to save: ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 1/300\n",
      "368/368 [==============================] - 220s 597ms/step - loss: 4.1410 - acc: 0.0197 - val_loss: 3.8202 - val_acc: 0.0567\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.82021, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 2/300\n",
      "368/368 [==============================] - 220s 598ms/step - loss: 3.8731 - acc: 0.0530 - val_loss: 3.5627 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.82021 to 3.56271, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 3/300\n",
      "368/368 [==============================] - 219s 596ms/step - loss: 3.5372 - acc: 0.1107 - val_loss: 3.4643 - val_acc: 0.1325\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.56271 to 3.46427, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 4/300\n",
      "368/368 [==============================] - 221s 601ms/step - loss: 3.2118 - acc: 0.1923 - val_loss: 3.1902 - val_acc: 0.1850\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.46427 to 3.19018, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 5/300\n",
      "368/368 [==============================] - 221s 600ms/step - loss: 2.8365 - acc: 0.2969 - val_loss: 3.0058 - val_acc: 0.2650\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.19018 to 3.00576, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 6/300\n",
      "368/368 [==============================] - 217s 590ms/step - loss: 2.5022 - acc: 0.4096 - val_loss: 2.7506 - val_acc: 0.2810\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.00576 to 2.75058, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 7/300\n",
      "368/368 [==============================] - 215s 585ms/step - loss: 2.1500 - acc: 0.4959 - val_loss: 2.4362 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.75058 to 2.43624, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 8/300\n",
      "368/368 [==============================] - 219s 596ms/step - loss: 1.8175 - acc: 0.6067 - val_loss: 2.3204 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.43624 to 2.32045, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 9/300\n",
      "368/368 [==============================] - 221s 601ms/step - loss: 1.4725 - acc: 0.6522 - val_loss: 2.0335 - val_acc: 0.4440\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.32045 to 2.03348, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 10/300\n",
      "368/368 [==============================] - 220s 597ms/step - loss: 1.2165 - acc: 0.7344 - val_loss: 1.9512 - val_acc: 0.4605\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.03348 to 1.95119, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 11/300\n",
      "368/368 [==============================] - 219s 596ms/step - loss: 0.9467 - acc: 0.8064 - val_loss: 1.7820 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.95119 to 1.78202, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 12/300\n",
      "368/368 [==============================] - 220s 598ms/step - loss: 0.7357 - acc: 0.8614 - val_loss: 1.6948 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.78202 to 1.69482, saving model to ../xception_model/0623_0526_3rd_xception_brand_preidct.hdf5\n",
      "Epoch 13/300\n",
      "137/368 [==========>...................] - ETA: 28s - loss: 0.6736 - acc: 0.8631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-7f20069c41ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_validation_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model(num_class=49)\n",
    "model_path = get_model_path(model_dir, model_name)\n",
    "\n",
    "callbacks1 = [\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                  patience=patient,\n",
    "                  mode='min',\n",
    "                  verbose=1),\n",
    "    #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "    ModelCheckpoint(filepath=model_path,\n",
    "                    monitor='val_loss',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='min'),\n",
    "]\n",
    "\n",
    "history_brand = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, batch_size),\n",
    "    verbose=1,\n",
    "    callbacks = callbacks1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail!!!\n",
    "\n",
    "Unbalanced data. 30 ~ 80.\n",
    "not enough to training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_each_models():\n",
    "    brands = df_train_brand.unique()\n",
    "    model_dict = {}\n",
    "    for brand in brands:\n",
    "        df = df_train[df_train['name']==brand]\n",
    "        num_class = df['class'].unique()\n",
    "        image_size = 299\n",
    "        batch_size = 8\n",
    "\n",
    "        X_train, X_val = split_traindf(df.iloc[:, :], train_size=0.7, stratify=True, label='class')\n",
    "\n",
    "        nb_train_sample = X_train.shape[0]\n",
    "        nb_validation_sample = X_val.shape[0]\n",
    "        print(nb_train_sample)\n",
    "        print(nb_validation_sample)\n",
    "        scale = 'rgb'\n",
    "        #scale = 'rgb'\n",
    "        train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                            val_df=X_val,\n",
    "                                                            train_dir=TRAIN_CROP_PATH,\n",
    "                                                            valid_dir=TRAIN_CROP_PATH,\n",
    "                                                            test_df=df_test,\n",
    "                                                            test_dir=TEST_CROP_PATH,\n",
    "                                                            image_size=image_size,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            scale=scale,\n",
    "                                                            target='class')\n",
    "\n",
    "        model = get_model(num_class=num_class)\n",
    "        model_path = get_model_path('brand_model', brand)\n",
    "        patient=3\n",
    "        callbacks1 = [\n",
    "            EarlyStopping(monitor='val_loss',\n",
    "                          patience=patient,\n",
    "                          mode='min',\n",
    "                          verbose=1),\n",
    "            #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "            ModelCheckpoint(filepath=model_path,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min'),\n",
    "        ]\n",
    "        epoch=50\n",
    "        history_brand = model.fit_generator(\n",
    "            train_gen,\n",
    "            steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "            epochs=epoch,\n",
    "            validation_data=validation_gen,\n",
    "            validation_steps=get_steps(nb_validation_sample, batch_size),\n",
    "            verbose=1,\n",
    "            callbacks = callbacks1\n",
    "        )\n",
    "        \n",
    "        model_dict.update({'history':history_brand})\n",
    "        model_dict.update({'model':model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 299\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_val = split_traindf(df_train.iloc[:, :], train_size=0.7, stratify=True)\n",
    "    \n",
    "\n",
    "nb_train_sample = X_train.shape[0]\n",
    "nb_validation_sample = X_val.shape[0]\n",
    "nb_test_sample = df_test.shape[0]\n",
    "scale = 'rgb'\n",
    "#scale = 'rgb'\n",
    "train_gen, validation_gen, test_gen = get_generator(train_df=X_train,\n",
    "                                                    val_df=X_val,\n",
    "                                                    train_dir=TRAIN_CROP_PATH,\n",
    "                                                    valid_dir=TRAIN_CROP_PATH,\n",
    "                                                    test_df=df_test,\n",
    "                                                    test_dir=TEST_CROP_PATH,\n",
    "                                                    image_size=image_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    scale=scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories=[]\n",
    "patient = 3\n",
    "lr = 0.0005\n",
    "model_dir = '../xception_model/'\n",
    "model_name = '_3rd_xception_rmsprop_batch8'\n",
    "epoch=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>model path to save: ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 1/300\n",
      "877/877 [==============================] - 200s 229ms/step - loss: 5.0125 - acc: 0.0301 - val_loss: 4.0876 - val_acc: 0.0729\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.08763, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 2/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 3.5755 - acc: 0.1365 - val_loss: 3.2075 - val_acc: 0.1983\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.08763 to 3.20749, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 3/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 2.5894 - acc: 0.3051 - val_loss: 2.1717 - val_acc: 0.4166\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.20749 to 2.17167, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 4/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 1.8829 - acc: 0.4629 - val_loss: 1.7922 - val_acc: 0.5231\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.17167 to 1.79215, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 5/300\n",
      "877/877 [==============================] - 197s 224ms/step - loss: 1.4075 - acc: 0.5836 - val_loss: 1.6864 - val_acc: 0.5494\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.79215 to 1.68641, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 6/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 1.0940 - acc: 0.6626 - val_loss: 1.5741 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.68641 to 1.57410, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 7/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 0.8852 - acc: 0.7201 - val_loss: 0.9870 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.57410 to 0.98704, saving model to ../xception_model/0623_0223_3rd_xception_rmsprop_batch8.hdf5\n",
      "Epoch 8/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 0.7493 - acc: 0.7617 - val_loss: 1.0603 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.98704\n",
      "Epoch 9/300\n",
      "877/877 [==============================] - 196s 224ms/step - loss: 0.6352 - acc: 0.8011 - val_loss: 1.0314 - val_acc: 0.7378\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98704\n",
      "Epoch 10/300\n",
      " 52/877 [>.............................] - ETA: 2:49 - loss: 0.4184 - acc: 0.8606"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-30bb941b6d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_validation_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model_path = get_model_path(model_dir, model_name)\n",
    "\n",
    "callbacks1 = [\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                  patience=patient,\n",
    "                  mode='min',\n",
    "                  verbose=1),\n",
    "    #ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = patient / 2, min_lr=0.00001, verbose=1, mode='min'),\n",
    "    ModelCheckpoint(filepath=model_path,\n",
    "                    monitor='val_loss',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='min'),\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=get_steps(nb_train_sample, batch_size),\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=get_steps(nb_validation_sample, batch_size),\n",
    "    verbose=1,\n",
    "    callbacks = callbacks1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(history, '_xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, model_path, test_gen, model_name, nb_test_sample, batch_size):\n",
    "    \n",
    "    model.load_weights(model_path)\n",
    "    test_gen.reset()\n",
    "    prediction = model.predict_generator(\n",
    "        generator=test_gen,\n",
    "        steps = get_steps(nb_test_sample, batch_size),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "\n",
    "    # Generator class dictionary mapping\n",
    "    \n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "    submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "    submission[\"class\"] = predictions\n",
    "    submission_fname = \"submissions/submissions{}.csv\".format(model_name)\n",
    "    submission.to_csv(submission_fname, index=False)\n",
    "    submission.head()\n",
    "    print('[*]sumission saved at {}'format(submission_fname))\n",
    "                      \n",
    "make_submission(model, model_path, test_gen, model_name, nb_test_sample, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base : batch 8 + more augmentation  + nodecay  + imgsize (224->299)\n",
    "\n",
    "rmsprop ->\n",
    "\n",
    "adam -> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
